# PoseD â€“ MediaPipeâ€‘powered Pose Detection API

![screenshot](images/sample.jpg)

**PoseD** is a tiny FastAPI service that turns Googleâ€¯MediaPipe (and, in the future, other frameworks) into a webâ€‘friendly API. Upload a clip, choose your output flavour, and receive either:

* **Landmarks overlaid** on the original video (MP4)
* **Transparent overlay** only (ProResÂ 4444Â MOV)
* **Both** overlayÂ + perâ€‘frame JSON coordinates in a single multipart response

> ðŸ–¥ï¸Â A quick demo of the transparent overlay on top of an HDR clip inÂ DaVinciÂ Resolve Studio: [https://youtu.be/PRFPsGsc\_hY](https://youtu.be/PRFPsGsc_hY)

---

## Project layout

```text
poseD/
â”œâ”€â”€ data/               â† sample input & result clips
â”œâ”€â”€ docker/             â† Dockerfile + ignore
â”œâ”€â”€ models/mediapipe/   â† pose_landmarker_heavy.task (mount readâ€‘only)
â”œâ”€â”€ src/posed/
â”‚   â”œâ”€â”€ app/main.py     â† FastAPI entryâ€‘point
â”‚   â””â”€â”€ inference/poseDetect.py
â””â”€â”€ docker-compose.yml
```

---

## QuickÂ start (Python environment)

```bash
# 1Â clone
git clone https://github.com/suhailphotos/Ayanna.git -b poseD
cd Ayanna

# 2Â Conda + Poetry (recommended)
conda env create -f environment.yml      # installs Pythonâ€¯3.11 + deps
conda activate posed
poetry config virtualenvs.create false   # install into conda env
poetry install --no-interaction

# 3Â run the API
uvicorn posed.app.main:app --reload --port 8000
```

Open [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) for interactive Swagger UI.

### Example request

```bash
curl -X POST "http://localhost:8000/pose?mode=overlay" \
     -F "file=@data/raw/videos/ana_sdr.mp4" \
     --output ana_sdr_pose_overlay.mp4
```

* `mode=overlay`Â âŸ¶ MP4 with skeleton lines
* `mode=transparent`Â âŸ¶ ProResÂ 4444Â MOV with alpha
* `mode=both`Â âŸ¶ multipart response containing `pose_overlay.mov` **and** `landmarks.json`

---

## QuickÂ start (Docker)

> **Image:** `suhailphotos/posed:latest`

```bash
# pull & run
mkdir -p outputs  # only if you want to mount a writeable dir

docker run --rm -p 8000:8000 \
  --name posed \
  --network everest \
  -v $(pwd)/models:/models:ro \
  suhailphotos/posed:latest
```

Or with the bundled **dockerâ€‘compose.yml**:

```bash
docker compose up -d    # builds or pulls & starts the container
```

---

## Features

| Mode                  | What you get                                 | Typical useâ€‘case                                |
| --------------------- | -------------------------------------------- | ----------------------------------------------- |
| **overlay** (default) | Original video + landmarks drawn (MP4/H.264) | Quick visual QA                                 |
| **transparent**       | RGBA overlay only (ProResÂ 4444Â MOV)          | Compositing over HDR / colourâ€‘managed timelines |
| **both**              | Multipart: overlayÂ MOV + `landmarks.json`    | Further ML analysis / motion graphics           |

### Landmarks.json format

```json
[
  [
    [0.3284, 0.3021, 0.0127, 0.99],
  ],
  [
    [0.3290, 0.3017, 0.0128, 0.99],
  ]
]
```

*`[x,Â y,Â z,Â visibility]` for each of the 33Â MediaPipe pose points.*

---

## Important source files

* **FastAPI router** â€“ [https://github.com/suhailphotos/Ayanna/blob/poseD/src/posed/app/main.py](https://github.com/suhailphotos/Ayanna/blob/poseD/src/posed/app/main.py)
* **Videoâ€‘side inference** â€“ [https://github.com/suhailphotos/Ayanna/blob/poseD/src/posed/inference/poseDetect.py](https://github.com/suhailphotos/Ayanna/blob/poseD/src/posed/inference/poseDetect.py)
* **Container recipe** â€“ [`docker/Dockerfile`](docker/Dockerfile)
* **Runtime orchestration** â€“ [`docker-compose.yml`](docker-compose.yml)

---

## Extending

* Add new models under `models/<framework>/â€¦` and update `POSE_MODEL` envâ€‘var.
* `poseDetect.py` is frameworkâ€‘agnostic â€“ swap the detector to plug in ONNX or TensorRT.
* Separate **/train** stub included for future fineâ€‘tuning scripts.

Pull requests welcome âœ¨

